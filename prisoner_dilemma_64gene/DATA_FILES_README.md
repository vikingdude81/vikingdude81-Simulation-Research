# Data Files Location Guide

## Large Dataset Files (Excluded from Git)

Due to GitHub's 100MB file size limit, the following large dataset files are **stored locally only**:

### Primary Datasets

1. **chaos_unified_GPU_1000runs_20251031_000616.json** (204.09 MB)
   - 1,000 evolutionary runs with GPU acceleration
   - 100,000 data points (1,000 runs × 100 generations)
   - Results: 999 convergent (99.9%), 1 periodic (0.1%), 0 chaotic
   - **Location**: Local machine only
   - **Required for**: All analysis scripts
   - **Generated by**: `run_unified_chaos_1000_GPU.py`

2. **chaos_dataset_100runs_20251030_223437.json** (~10 MB)
   - Legacy 100-run dataset
   - **Warning**: Severely overfitted, unreliable for conclusions
   - **Use only for**: Comparison analysis showing small-sample pitfalls
   - **Location**: Local machine only
   - **Generated by**: Original data collection script

### Analysis Results (Included in Git)

The following **analysis outputs** are included in the repository:

✅ **outputs/ml_evolution/** - ML analysis results and visualizations
✅ **RESEARCH_FINDINGS_COMPREHENSIVE.md** - Complete scientific report
✅ All Python analysis scripts (.py files)

## How to Reproduce Analysis

### Option 1: Generate Data Locally (Recommended)

```powershell
cd prisoner_dilemma_64gene

# Quick 10-run test (validation)
echo "yes" | python test_unified_chaos_10runs.py

# Full 1,000-run experiment (27.8 minutes on RTX 4070 Ti)
echo "yes" | python run_unified_chaos_1000_GPU.py
```

**Requirements**:
- NVIDIA GPU with CUDA support (tested on RTX 4070 Ti)
- PyTorch 2.6.0+cu124
- Python 3.13
- 27.8 minutes compute time

**Output**: `chaos_unified_GPU_1000runs_YYYYMMDD_HHMMSS.json`

### Option 2: Request Data Files

If you need the exact dataset files for reproducibility:

1. **Contact**: Repository maintainer (vikingdude81)
2. **Alternative Storage**: Consider using:
   - Git LFS (Large File Storage)
   - External hosting (Google Drive, Dropbox, etc.)
   - Research data repositories (Zenodo, figshare)

## Analysis Scripts (All Included)

All analysis scripts are in the repository and can be run immediately after generating or obtaining data:

```powershell
# Comprehensive ML analysis
python analyze_1000runs_comprehensive.py

# Gene 30 investigation
python investigate_gene_30.py

# Periodic outlier forensics
python investigate_periodic_outlier.py

# Trajectory clustering
python trajectory_clustering.py

# 100 vs 1,000 comparison
python compare_100_vs_1000.py
```

**Note**: Scripts automatically look for the latest `chaos_unified_GPU_1000runs_*.json` file in the current directory.

## File Size Reference

| File | Size | Status | Purpose |
|------|------|--------|---------|
| `chaos_unified_GPU_1000runs_20251031_000616.json` | 204.09 MB | Local only | Primary dataset |
| `chaos_dataset_100runs_20251030_223437.json` | ~10 MB | Local only | Comparison baseline |
| `RESEARCH_FINDINGS_COMPREHENSIVE.md` | ~50 KB | ✅ In Git | Scientific report |
| Analysis scripts (14 files) | ~200 KB total | ✅ In Git | Reproducibility |
| Visualizations (outputs/) | ~2 MB | ✅ In Git | Results |

## Backup Strategy

**Local Backup Locations**:
- Primary: `c:\Users\akbon\OneDrive\Documents\PRICE-DETECTION-TEST-1\PRICE-DETECTION-TEST-1\prisoner_dilemma_64gene\`
- Cloud: OneDrive (automatically synced)

**Recommended External Backup**:
- Upload to research data repository (Zenodo, figshare)
- Create compressed archive for long-term storage
- Document exact reproduction steps in paper/report

## Citation

If using this data in publications:

```
GPU-Accelerated Evolutionary Prisoner's Dilemma Dataset (2025)
1,000 runs, 100,000 data points, 64-gene strategy encoding
Generated: October 31, 2025
Hardware: NVIDIA RTX 4070 Ti (12.88 GB VRAM)
Software: PyTorch 2.6.0+cu124, Python 3.13
```

## Questions?

See `RESEARCH_FINDINGS_COMPREHENSIVE.md` for complete methodology and results.
